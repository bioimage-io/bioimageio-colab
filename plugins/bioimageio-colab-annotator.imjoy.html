<config lang="json">
{
  "name": "BioImage.IO Colab Annotator",
  "type": "iframe",
  "tags": [],
  "ui": "",
  "version": "0.1.0",
  "cover": "",
  "description": "Collaborative Annotator for BioImage.IO with Automated Segmentation",
  "icon": "extension",
  "inputs": null,
  "outputs": null,
  "api_version": "0.1.8",
  "env": "",
  "permissions": [],
  "requirements": [
    "https://cdn.jsdelivr.net/npm/imjoy-rpc@0.5.6/dist/hypha-rpc-websocket.min.js"
  ],
  "dependencies": []
}
</config>

<script lang="javascript">
class BioImageIOColabAnnotator {
    constructor() {
        this.image = null; // Current image
        this.mask = null; // Current mask
        this.filename = null; // Filename of the current image
        this.newname = null; // New name for the annotation file
        this.imageLayer = null; // Layer displaying the image
        this.annotationLayer = null; // Layer displaying the annotations
        this.edgeColor = "magenta"; // Default edge color for annotations
        this.modelName = "vit_b"; // Model name for the embeddings
        this.embeddingIsCalculated = false; // Flag to check if embeddings are calculated
    }

    async setup() {
        // No setup actions required for now
    }

    async run(ctx) {
        // Extract configuration settings
        const config = ctx.config || {};
        const serverUrl = config.server_url || "https://ai.imjoy.io";
        const annotationServiceId = config.annotation_service_id || "bioimageio-colab-annotation";  // default for testing plugin
        const modelServiceId = config.model_service_id || "oNwLbCSSNbiWrpr7h85F9f/ardFE2rx8wFB69JbbUGFfp:bioimageio-colab-model";  // default for testing plugin
        
        // Create and display the viewer window
        const viewer = await api.createWindow({src: "https://kaibu.org/#/app", fullscreen: true});
        await api.showMessage(`Connecting to server ${serverUrl}....`);
        // Login before connecting and then use userid instead of new client_id
        // TODO: Add login functionality

        // Connect to the Hypha server
        const server = await hyphaWebsocketClient.connectToServer({
            server_url: serverUrl,
            token: config.token,
            workspace: config.workspace,
        });

        // Get the bioimageio-colab service from the server
        let biocolab;
        try {
            biocolab = await server.getService(annotationServiceId);
        } catch (e) {
            await api.alert(`Failed to get the bioimageio-colab annotation service (id=${annotationServiceId}). (Error: ${e})`);
            return;
        }

        // Get the model service from the server
        let model;
        try {
            model = await server.getService(modelServiceId);
        } catch (e) {
            await api.alert(`Failed to get the bioimageio-colab model service (id=${modelServiceId}). (Error: ${e})`);
            return;
        }

        // Get an annotator client ID
        const clientID = await model.client_id();

        // Function to get a new image and set up the viewer
        const getImage = async () => {
            if (this.image !== null) {
                // Remove existing layers if there is any image loaded
                await viewer.remove_layer({id: this.imageLayer.id});
                await viewer.remove_layer({id: this.annotationLayer.id});
            }

            // Fetch a random image from the service
            [this.image, this.filename, this.newname] = await biocolab.get_random_image();
            this.imageLayer = await viewer.view_image(this.image, {name: "image"});

            // Reset the predictorId for the new image
            this.embeddingIsCalculated = false;
            await model.reset_embedding(clientID);

            // Add the annotation functionality to the interface
            this.annotationLayer = await viewer.add_shapes([], {
                shape_type: "polygon",
                draw_edge_color: this.edgeColor,
                name: "annotation",
                _rintf: true,
                // Callback for adding a new feature (annotation point)
                add_feature_callback: async (shape) => {
                    if (shape.geometry.type === "Point") {
                        // The point coordinates need to be reversed to match the coordinate convention of SAM
                        const pointCoords = [shape.geometry.coordinates.reverse()];
                        const pointLabels = pointCoords.map(() => 1); // All points have a label of 1

                        // Compute embeddings if not already computed for the image
                        if (!this.embeddingIsCalculated) {
                            api.showMessage("Computing embeddings for the image...");
                            try {
                                await model.compute_embedding(clientID, this.modelName, this.image);
                            } catch (e) {
                                await api.showMessage(`Failed to compute embeddings for the image. (Error: ${e})`);
                                return;
                            }
                            this.embeddingIsCalculated = true;
                        }

                        // Perform segmentation
                        api.showMessage("Segmenting...");
                        const features = await model.segment(clientID, pointCoords, pointLabels);

                        // Add the segmented features as polygons to the annotation layer
                        for (let coords of features) {
                            const polygon = {
                                type: "Feature",
                                coordinates: coords,
                                geometry: {
                                    type: "Polygon",
                                    coordinates: [coords],
                                },
                                properties: {
                                    edge_color: this.edgeColor,
                                    edge_width: 2,
                                    size: 7,
                                },
                            };
                            this.annotationLayer.add_feature(polygon);
                        }
                    }
                }
            });
        };

        // Function to save the annotation
        const saveAnnotation = async () => {
            if (!this.annotationLayer) return;
            const annotation = await this.annotationLayer.get_features();
            if (annotation.features.length > 0) {
                await biocolab.save_annotation(this.filename, this.newname, annotation, [this.image._rshape[0], this.image._rshape[1]]);
                await api.showMessage(`Annotation Saved to ${this.filename}`);
            } else {
                await api.showMessage("Skip saving annotation");
            }
        };

        // Function to load the next image
        const nextImage = async () => {
            await saveAnnotation();
            await getImage();
        };

        // Add a control widget with a button to load the next image
        await viewer.add_widget({
            _rintf: true,
            name: "Control",
            type: "control",
            elements: [
                {
                    type: "button",
                    label: "Save Annotation",
                    callback: nextImage,
                }
            ],
        });

        // Load the initial image
        await getImage();
        await api.showMessage("Ready to annotate!");
    }
}

// Export the annotator class
api.export(new BioImageIOColabAnnotator());
</script>

