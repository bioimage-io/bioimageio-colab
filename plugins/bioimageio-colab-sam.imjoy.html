<docs>
[TODO: write documentation for this plugin.]
</docs>

<config lang="json">
{
  "name": "BioImage.IO Colab Annotator",
  "type": "iframe",
  "tags": [],
  "ui": "",
  "version": "0.1.0",
  "cover": "",
  "description": "Collabrative Annotator for BioImage.IO",
  "icon": "extension",
  "inputs": null,
  "outputs": null,
  "api_version": "0.1.8",
  "env": "",
  "permissions": [],
  "requirements": ["https://cdn.jsdelivr.net/npm/imjoy-rpc@0.5.6/dist/hypha-rpc-websocket.min.js", "https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"],
  "dependencies": []
}
</config>

<script lang="javascript">
const N_PIXEL_NEIGHBOR = 8

function padMask(unpaddedMask, unPaddedWidth, unPaddedHeight) {
  const paddedWidth = unPaddedWidth + 2
  const paddedHeight = unPaddedHeight + 2

  const paddedMask = new Int8Array(paddedWidth * paddedHeight)

  for (let y = 0; y < unPaddedHeight; y++) {
    for (let x = 0; x < unPaddedWidth; x++) {
      const unPaddedIdx = y * unPaddedWidth + x
      const paddedIdx = (y + 1) * paddedWidth + (x + 1)

      paddedMask[paddedIdx] = unpaddedMask[unPaddedIdx] === 0 ? 0 : 1
    }
  }

  return paddedMask
}

// realigns contours such that the points they contain are with respect
// to the unpadded binary mask
function unpadContours(contours) {
  const unpaddedContours = []

  for (const contour of contours) {
    unpaddedContours.push({
      ...contour,
      points: contour.points.map(p => ({ x: p.x - 1, y: p.y - 1 }))
    })
  }

  return unpaddedContours
}

function _f_ij(F, width, height) {
  return {
    get: (i, j) => F[i * width + j],
    set: (i, j, value) => {
      F[i * width + j] = value
    }
  }
}

// give pixel neighborhood counter-clockwise ID's for
// easier access with findContour algorithm
function neighborIdxToCoord(i, j, id) {
  switch (id) {
    case 0:
      return [i, j + 1]
    case 1:
      return [i - 1, j + 1]
    case 2:
      return [i - 1, j]
    case 3:
      return [i - 1, j - 1]
    case 4:
      return [i, j - 1]
    case 5:
      return [i + 1, j - 1]
    case 6:
      return [i + 1, j]
    case 7:
      return [i + 1, j + 1]
    default:
      // return null;
      throw new Error(`Incorrect id, (${id}), must be in [0, 7]`)
  }
}

function neighborCoordToIdx(baseI, baseJ, neighborI, neighborJ) {
  let di = neighborI - baseI
  let dj = neighborJ - baseJ

  if (di === 0 && dj === 1) {
    return 0
  }
  if (di === -1 && dj === 1) {
    return 1
  }
  if (di === -1 && dj === 0) {
    return 2
  }
  if (di === -1 && dj === -1) {
    return 3
  }
  if (di === 0 && dj === -1) {
    return 4
  }
  if (di === 1 && dj === -1) {
    return 5
  }
  if (di === 1 && dj === 0) {
    return 6
  }
  if (di === 1 && dj === 1) {
    return 7
  }
  // return -1;
  throw new Error(`Cannot find id with di ${di}, dj ${dj}`)
}

function logNeighbors(fij, baseI, baseJ, startIdx, offset, logMessage) {
  const neighborVals = ["_", "_", "_", "_", "_", "_", "_", "_"]

  for (let ccwIdx = 0; ccwIdx < N_PIXEL_NEIGHBOR; ccwIdx++) {
    let neighborIdx =
      (ccwIdx + startIdx + offset + N_PIXEL_NEIGHBOR * 2) % N_PIXEL_NEIGHBOR
    let ij = neighborIdxToCoord(baseI, baseJ, neighborIdx)

    neighborVals[neighborIdx] =
      neighborIdx === startIdx + offset
        ? `(${fij.get(ij[0], ij[1])})`
        : ` ${fij.get(ij[0], ij[1])} `
  }

  logMessage && console.log(logMessage)
  console.log(`neighborhood: (${baseI}, ${baseJ})`)
  console.log(
    `|${neighborVals[3]}|${neighborVals[2]}|${neighborVals[1]}|\n|${
      neighborVals[4]
    }| ${fij.get(baseI, baseJ)} |${neighborVals[0]}|\n|${neighborVals[5]}|${
      neighborVals[6]
    }|${neighborVals[7]}|`
  )
}

/**
 * First counter-clockwise non-zero element in neighborhood
 * also responsible in determining if the neighbor directly to
 * the right of the base coordinate is crossed (inspected)
 *
 * @param baseI The i coordinate of the point to search the neighborhood of
 * @param baseJ The j coordinate of the point to search the neighbrohood of
 * @param neighborI The i coordinate of the first point in the neighborhood to search
 *                  should i + (1, 0, or -1)
 * @param neighborJ The j coordinate of the first point in the neighborhood to search
 *                  should j + (1, 0, or -1)
 * @param offset An offset counterclockwise from the base point
 * @return object
 * @parameter ij: The (i,j) coords of the non-zero neighbor or null if absent
 * @parameter rightExamined: wether or not the right neighbor was inspected
 **/
function ccwNon0(fij, w, h, baseI, baseJ, neighborI, neighborJ, offset) {
  let rightExamined = false

  let startIdx = neighborCoordToIdx(baseI, baseJ, neighborI, neighborJ)
  for (let ccwIdx = 0; ccwIdx < N_PIXEL_NEIGHBOR; ccwIdx++) {
    let neighborIdx =
      (ccwIdx + startIdx + offset + N_PIXEL_NEIGHBOR * 2) % N_PIXEL_NEIGHBOR

    rightExamined = neighborIdx === 0 ? true : rightExamined

    let ij = neighborIdxToCoord(baseI, baseJ, neighborIdx)

    if (fij.get(ij[0], ij[1]) !== 0) {
      return { ij, rightExamined }
    }
  }
  process.env.NODE_ENV !== "production" &&
    logNeighbors(
      fij,
      baseI,
      baseJ,
      startIdx,
      offset,
      "ccw scan - nothing found"
    )
  return { ij: null, rightExamined }
}

/**
 * First clockwise non-zero element in neighborhood
 * @param baseI The i coordinate of the point to search the neighborhood of
 * @param baseJ The j coordinate of the point to search the neighbrohood of
 * @param neighborI The i coordinate of the first point in the neighborhood to search
 *                  should i + (1, 0, or -1)
 * @param neighborJ The j coordinate of the first point in the neighborhood to search
 *                  should j + (1, 0, or -1)
 * @param offset An offset counterclockwise from the base point
 * @return The (i,j) coords of the non-zero neighbor or null if absent
 **/
function cwNon0(fij, w, h, baseI, baseJ, neighborI, neighborJ, offset) {
  let startIdx = neighborCoordToIdx(baseI, baseJ, neighborI, neighborJ)
  for (let ccwIdx = 0; ccwIdx < N_PIXEL_NEIGHBOR; ccwIdx++) {
    let neighborIdx =
      (-ccwIdx + startIdx - offset + N_PIXEL_NEIGHBOR * 2) % N_PIXEL_NEIGHBOR
    let ij = neighborIdxToCoord(baseI, baseJ, neighborIdx)
    if (fij.get(ij[0], ij[1]) !== 0) {
      return ij
    }
  }
  return null
}

/**
 * Find contours in a binary image
 * <p>
 * Implements Suzuki, S. and Abe, K.
 * Topological Structural Analysis of Digitized Binary Images by Border Following.
 * <p>
 * See source code for step-by-step correspondence to the paper's algorithm
 * description.
 * @param  F    The "Frame" (bitmap), stored in 1-dimensional row-major form.
 *              0=background, 1=foreground, will be modified by the function
 *              to hold semantic information
 * @param  width    Width of the bitmap
 * @param  height    Height of the bitmap
 * @return      An array of contours found in the image.
 * @see         Contour
 */
function findContours(F, width, height) {
  // Topological Structural Analysis of Digitized Binary Images by Border Following.
  // Suzuki, S. and Abe, K., CVGIP 30 1, pp 32-46 (1985)

  let contours = []

  // Without loss of generality, we assume that 0-pixels fill the frame
  // of a binary picture
  for (let i = 1; i < height - 1; i++) {
    F[i * width] = 0
    F[i * width + width - 1] = 0
  }
  for (let i = 0; i < width; i++) {
    F[i] = 0
    F[width * height - 1 - i] = 0
  }

  // Set nitially NBD to 1
  // (the frame of F forms a special hole border and gets the sequential number 1;
  //  NBD stands for the sequential number of the current border)
  let NBD = 1

  // Scan the picture with a TV raster and perform the following steps
  // for each pixel such that fij != 0. Every time we begin to scan a
  // new row of the picture, reset LNBD to 1.
  // LNDB stands for the sequential number of the (outer or hole) border
  // encountered most recently
  let LNBD = 1

  // The pixel located in the ith row and jth column is represented by the
  // row number (i, j)
  // fij is the value at coord (i,j) => F[i * width + j]
  const fij = _f_ij(F, width, height)

  // the row number i increases from top to bottom
  for (let iRaster = 1; iRaster < height - 1; iRaster++) {
    LNBD = 1

    // the column number j from left to right
    for (let jRaster = 1; jRaster < width - 1; jRaster++) {
      let [i2CwStart, j2CwStart] = [0, 0]

      // scan until fij != 0
      if (fij.get(iRaster, jRaster) === 0) {
        continue
      }

      // current border 0 used in (2)
      let B = {
        isHole: undefined,
        seqNum: undefined,
        points: [{ y: iRaster, x: jRaster }]
      }

      // (1) Select one of the following (1-a, 1-b, or 1-c):

      // (1-a) If fij = 1 and fi, j-1 = 0, then decide that the pixel
      //     (i, j) is the border following starting point of an outer
      //     border, increment NBD, and (i2, j2) <- (i, j - 1).
      if (
        fij.get(iRaster, jRaster) === 1 &&
        fij.get(iRaster, jRaster - 1) === 0
      ) {
        NBD++
        ;[i2CwStart, j2CwStart] = [iRaster, jRaster - 1]
        B.isHole = false
        B.seqNum = NBD

        // (1-b) Else if fij >= 1 and fi,j+1 = 0, then decide that the
        //     pixel (i, j) is the border following starting point of a
        //     hole border, increment NBD, (i2, j2) <- (i, j + 1), and
        //     LNBD + fij in case fij > 1.
      } else if (
        fij.get(iRaster, jRaster) >= 1 &&
        fij.get(iRaster, jRaster + 1) === 0
        // not in original paper
        // account for special case for outer border covered by hole border
        // && fij.get(iRaster, jRaster - 1) !== 0
      ) {
        NBD++
        ;[i2CwStart, j2CwStart] = [iRaster, jRaster + 1]
        if (fij.get(iRaster, jRaster) > 1) {
          LNBD = fij.get(iRaster, jRaster)
        }
        B.isHole = true
        B.seqNum = NBD
      } else {
        // (1-c) Otherwise, go to (4).
        //
        // (4) If fij != 1, then LNBD <- |fij| and resume the raster
        //     scan from pixel (i,j+1). The algorithm terminates when the
        //     scan reaches the lower right corner of the picture
        if (fij.get(iRaster, jRaster) !== 1) {
          LNBD = Math.abs(fij.get(iRaster, jRaster))
        }
        continue
      }

      // (2) Depending on the types of the newly found border
      //     and the border with the sequential number LNBD
      //     (i.e., the last border met on the current row),
      //     decide the parent of the current border as shown in Table 1.
      //
      // TABLE 1
      // Decision Rule for the Parent Border of the Newly Found Border B
      // ----------------------------------------------------------------
      // Type of border B'
      // \    with the sequential
      //     \     number LNBD
      // Type of B \                Outer border         Hole border
      // ---------------------------------------------------------------
      // Outer border               The parent border    The border B'
      //                            of the border B'
      //
      // Hole border                The border B'      The parent border
      //                                               of the border B'
      // ----------------------------------------------------------------

      contours.push(B)

      // default Bprime
      let Bprime = {
        seqNum: LNBD,
        points: [],
        parent: LNBD
      }

      // replace Bprime with already found border of that seqNum,
      // if available
      for (let c = 0; c < contours.length; c++) {
        if (contours[c].seqNum === LNBD) {
          Bprime = contours[c]
          break
        }
      }

      if (Bprime.isHole) {
        if (B.isHole) {
          B.parent = Bprime.parent
        } else {
          B.parent = Bprime.seqNum
        }
      } else {
        if (B.isHole) {
          B.parent = Bprime.seqNum
        } else {
          B.parent = Bprime.parent
        }
      }

      // (3) From the starting point (i, j), follow the detected border:
      //     this is done by the following substeps (3.1) through (3.5).

      // (3.1) Starting from (i2, j2), look around clockwise the pixels
      //       in the neigh- borhood of (i, j) and find a nonzero pixel.
      //       Let (i1, j1) be the first found nonzero pixel. If no nonzero
      //       pixel is found, assign -NBD to fij and go to (4).
      let i1j1 = cwNon0(
        fij,
        width,
        height,
        iRaster,
        jRaster,
        i2CwStart,
        j2CwStart,
        0
      )
      if (i1j1 === null) {
        fij.set(iRaster, jRaster, -NBD)
        //go to (4)
        if (fij.get(iRaster, jRaster) !== 1) {
          LNBD = Math.abs(fij.get(iRaster, jRaster))
        }
        continue
      }
      let [i1CwFound, j1CwFound] = i1j1

      // (3.2) (i2, j2) <- (i1, j1) and (i3,j3) <- (i, j).
      let [i2PrevStep, j2PrevStep] = [i1CwFound, j1CwFound]
      let [i3CurrStep, j3CurrStep] = [iRaster, jRaster]

      // walk the border
      while (true) {
        // (3.3) Starting from the next elementof the pixel (i2, j2)
        //       in the counterclockwise order, examine counterclockwise
        //       the pixels in the neighborhood of the current pixel (i3, j3)
        //       to find a nonzero pixel and let the first one be (i4, j4).

        let { ij: i4j4, rightExamined } = ccwNon0(
          fij,
          width,
          height,
          i3CurrStep,
          j3CurrStep,
          i2PrevStep,
          j2PrevStep,
          1
        )

        if (i4j4 === null) {
          process.env.NODE_ENV !== "production" &&
            console.warn(
              `i4j4 is invalid: i ${iRaster}, j ${jRaster}, i1 ${i1CwFound}, j1 ${j1CwFound}, i2 ${i2PrevStep}, j2 ${j2PrevStep}, i3 ${i3CurrStep}, j3 ${j3CurrStep}, i4j4j ${i4j4}`
            )
          // break;
        }

        var [i4CcwFound, j4CcwFound] = i4j4

        // save the point
        contours[contours.length - 1].points.push({
          y: i4CcwFound,
          x: j4CcwFound
        })

        // (3.4) Change the value fi3j3 of the pixel (i3, j3) as follows:

        // (3.4-a) If the pixel (i3, j3 + 1) is a O-pixel examined in the
        //     substep (3.3) then fi3, j3 <-  -NBD.
        if (fij.get(i3CurrStep, j3CurrStep + 1) === 0) {
          fij.set(
            i3CurrStep,
            j3CurrStep,
            // B.isHole to account for donut, see find-contours.test.ts
            rightExamined || B.isHole ? -NBD : NBD
          )

          // (3.4-b) If the pixel (i3, j3 + 1) is not a O-pixel examined
          //     in the substep (3.3) and fi3j3 = 1, then fi3j3 <- NBD.
        } else if (
          fij.get(i3CurrStep, j3CurrStep + 1) !== 0 &&
          fij.get(i3CurrStep, j3CurrStep) === 1
        ) {
          fij.set(i3CurrStep, j3CurrStep, NBD)
        } else {
          //(3.4-c) Otherwise, do not change fi3j3.
        }

        // (3.5) If (i4, j4) = (i, j) and (i3, j3) = (i1, j1)
        //      (coming back to the starting point), then go to (4);
        if (
          i4CcwFound === iRaster &&
          j4CcwFound === jRaster &&
          i3CurrStep === i1CwFound &&
          j3CurrStep === j1CwFound
        ) {
          if (fij.get(iRaster, jRaster) !== 1) {
            LNBD = Math.abs(fij.get(iRaster, jRaster))
          }
          break

          // otherwise, (i2, j2) <- (i3, j3),(i3, j3) <- (i4, j4),
          // and go back to (3.3).
        } else {
          ;[i2PrevStep, j2PrevStep] = [i3CurrStep, j3CurrStep]
          ;[i3CurrStep, j3CurrStep] = [i4CcwFound, j4CcwFound]
        }
      }
    }
  }
  return unpadContours(contours)
}


// square distance between 2 points
function getSqDist(p1, p2) {
  var dx = p1.x - p2.x,
    dy = p1.y - p2.y

  return dx * dx + dy * dy
}

// square distance from a point to a segment
function getSqSegDist(p, p1, p2) {
  var x = p1.x,
    y = p1.y,
    dx = p2.x - x,
    dy = p2.y - y

  if (dx !== 0 || dy !== 0) {
    var t = ((p.x - x) * dx + (p.y - y) * dy) / (dx * dx + dy * dy)

    if (t > 1) {
      x = p2.x
      y = p2.y
    } else if (t > 0) {
      x += dx * t
      y += dy * t
    }
  }

  dx = p.x - x
  dy = p.y - y

  return dx * dx + dy * dy
}

// basic distance-based simplification
function simplifyRadialDist(points, sqTolerance) {
  var prevPoint = points[0]
  var newPoints = [prevPoint]
  var point

  for (var i = 1, len = points.length; i < len; i++) {
    point = points[i]

    if (getSqDist(point, prevPoint) > sqTolerance) {
      newPoints.push(point)
      prevPoint = point
    }
  }

  if (point && prevPoint !== point) newPoints.push(point)

  return newPoints
}

function simplifyDPStep(points, first, last, sqTolerance, simplified) {
  let maxSqDist = sqTolerance
  let index = 0

  for (var i = first + 1; i < last; i++) {
    var sqDist = getSqSegDist(points[i], points[first], points[last])

    if (sqDist > maxSqDist) {
      index = i
      maxSqDist = sqDist
    }
  }

  if (maxSqDist > sqTolerance) {
    if (index - first > 1)
      simplifyDPStep(points, first, index, sqTolerance, simplified)
    simplified.push(points[index])
    if (last - index > 1)
      simplifyDPStep(points, index, last, sqTolerance, simplified)
  }
}

// simplification using Ramer-Douglas-Peucker algorithm
function simplifyDouglasPeucker(points, sqTolerance) {
  var last = points.length - 1

  var simplified = [points[0]]
  simplifyDPStep(points, 0, last, sqTolerance, simplified)
  simplified.push(points[last])

  return simplified
}

/**
 * Polyline simplification using a combination of Douglas-Peucker and Radial Distance algorithm.
 * @param points Array of points (Polyline).
 * @param tolerance [default = 1] Affects the amount of simplification (in the same metric as the point coordinates).
 * @param highestQuality [default = true] Excludes distance-based preprocessing step which leads to highest quality simplification but runs ~10-20 times slower.
 * @returns Array of simplified points.
 */
function simplifyPolygon(points, tolerance = 1, highestQuality = true) {
  if (points.length <= 2) return points

  const sqTolerance = tolerance * tolerance

  points = highestQuality ? points : simplifyRadialDist(points, sqTolerance)
  points = simplifyDouglasPeucker(points, sqTolerance)
  return points
}

function toFloat32Tensor(array){
    const dst = new ArrayBuffer(array._rvalue.byteLength);
    new Uint8Array(dst).set(new Uint8Array(array._rvalue));
    return new ort.Tensor('float32', new Float32Array(dst), array._rshape)
}
    
class BioImageIOColabSAM {
    constructor() {
        this.image = null;
        this.mask = null;
        this.filename = null;
        this.newname = null;
        this.imageLayer = null;
        this.annotationLayer = null;
    }

    async setup() {
        // const session = await ort.InferenceSession.create('https://raw.githubusercontent.com/microsoft/onnxruntime-inference-examples/main/js/quick-start_onnxruntime-web-script-tag/model.onnx'); // , executionProviders: ['webgpu']

        // // prepare inputs. a tensor need its corresponding TypedArray as data
        // const dataA = Float32Array.from([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]);
        // const dataB = Float32Array.from([10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120]);
        // const tensorA = new ort.Tensor('float32', dataA, [3, 4]);
        // const tensorB = new ort.Tensor('float32', dataB, [4, 3]);

        // // prepare feeds. use model input names as keys.
        // const feeds = { a: tensorA, b: tensorB };

        // // feed inputs and run
        // const results = await session.run(feeds);

        // // read from results
        // const dataC = results.c.data;
        // await api.showMessage(`data of result tensor 'c': ${dataC}`);
    }
    
    async run(ctx){
        const config = ctx.config || {};
        const serviceId = config.service_id || "bioimageio-colab-sam";
        const serverUrl = config.server_url || "https://ai.imjoy.io";
        const viewer = await api.createWindow({src: "https://kaibu.org/#/app", fullscreen: true});
        await api.showMessage(`Connecting to server ${serverUrl}....`);
        try{
            const server = await hyphaWebsocketClient.connectToServer({server_url: serverUrl, token: config.token, workspace: config.workspace});
            this.biocolab = await server.getService(serviceId);
            if(await this.biocolab.ping() === "pong"){
                await api.showMessage(`Connected to server.`)
                // const modelId = "vit_b" 
                // debugger
                // const image_embeddings = toFloat32Tensor(await this.biocolab.compute_embeddings(modelId, null))
                // const point_coords = new ort.Tensor('float32', Float32Array.from([100, 100]), [1, 1, 2]); // batch, num_point, coord(2)
                // const point_labels = new ort.Tensor('float32', Float32Array.from([1,]), [1, 1]); // batch, num_point
                // const mask_input = new ort.Tensor('float32', new Float32Array(new ArrayBuffer(1*1*256*256*4)), [1, 1, 256, 256])
                // const has_mask_input = new ort.Tensor('float32', Float32Array.from([0]), [1,])
                // const orig_im_size = new ort.Tensor('float32', Float32Array.from([520, 704]), [2,])
                // const feeds = { image_embeddings, point_coords, point_labels, mask_input, has_mask_input, orig_im_size };
                // console.log('============feeds============', feeds)
                // const onnxUrl = await this.biocolab.get_onnx(modelId)
                // const session = await ort.InferenceSession.create(onnxUrl);
                // const results = await session.run(feeds);
                // console.log('==========results===========', results)
                // await api.alert("ONNX:" + onnxUrl)
            }
        }
        catch(e){
            console.error(e)
            await api.alert(`Failed to get the bioimageio-colab service (id=${serviceId}), please make sure you started the server, error: ${e}`)
            return;
        }

        // Define image reading and displaying function
        const getImage = async () => {
            if (this.image !== null) {
                await viewer.remove_layer({id: this.imageLayer.id});
                await viewer.remove_layer({id: this.annotationLayer.id});
            }

            this.image = await this.biocolab.get_example_image();
            this.imageLayer = await viewer.view_image(this.image, {name: "image"});
            // Add the annotation functionality to the interface
            this.annotationLayer = await viewer.add_shapes([], {
                name: 'Annotation Layer',
                _rintf: true,
                add_feature_callback: async (shape) => {
                    console.log(shape)
                    if (shape.geometry.type === "Point") {
                        console.log("add point at", shape.geometry.coordinates)
                        if(!this.predictor_id)
                            this.predictor_id = await this.biocolab.compute_embeddings("vit_b", null, false)
                        // The point coordinates need to be reversed to match the coordinate convention of SAM.
                        const point_coords = [shape.geometry.coordinates.reverse()]
                        
                        const point_labels = []
                        for(let coord of point_coords){
                            point_labels.push(1)
                        }
                        const features = await this.biocolab.segment(this.predictor_id, point_coords, point_labels)
        
                        for(let coords of features){
                            console.log("coords", coords)
                            const polygon = {
                                type: "Feature",
                                coordinates: coords,
                                geometry: {
                                    type: "Polygon",
                                    coordinates: [coords],
                                },
                                properties: {
                                    edgecolor: "#FF0000",
                                    edge_width: 2,
                                    face_color: "#FF00000F",
                                    size: 7,
                                },
                            }
                            this.annotationLayer.add_feature(polygon)
                        }
                    }
                },
            })
        };

//         const saveAnnotation = async () => {
//             if(!this.annotationLayer) return;
//             const annotation = await this.annotationLayer.get_features();
//             if(annotation.features.length > 0){
//                 await this.biocolab.save_annotation(this.filename, this.newname, annotation, [this.image._rshape[0], this.image._rshape[1]]);
//                 await api.showMessage("Annotation Saved to " + this.filename);
//             }
//             else{
//                 await api.showMessage("Skip saving annotation");
//             }
            
//         };

        const segmentImage = async (option) => {
            // const predictor_id = await this.biocolab.compute_embeddings("vit_b", null, false)
            // const point_coords = [[100, 120]]
            // const point_labels = [1]
            // const features = await this.biocolab.segment(predictor_id, point_coords, point_labels)
            // console.log('=============result===============', features)
            // // await this.annotationLayer.add_features(features)
            // // await viewer.remove_layer(self.annotationLayer)
            // self.annotationLayer = await viewer.add_shapes(
            //     features,
            //     {shape_type: "polygon",
            //     edge_color: "red",
            //     name: "prediction"},
            // )
        };

        // await viewer.add_widget({
        //     _rintf: true,
        //     name: "Control",
        //     type: "control",
        //     elements: [
        //         {
        //             type: "button",
        //             label: "Segment Image",
        //             callback: segmentImage,
        //         }
        //     ],
        // });
        
        await getImage()

        await api.showMessage("Ready to annotate!");
    }
}

api.export(new BioImageIOColabSAM());
</script>
